import matplotlib.pyplot as plt
import keras
from keras.models import Sequential, Model
from keras.layers import Dense
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from keras import optimizers
from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau
from keras_vggface.vggface import VGGFace
from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization
from keras.engine import Model
from keras.layers import Input
import tensorflow as tf
import cv2
from tqdm import tqdm
import os
import numpy as np
from keras.applications.resnet50 import ResNet50
from sklearn.metrics import confusion_matrix
from keras.utils import plot_model

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
tf.keras.backend.set_session(tf.Session(config=config))


# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'


train_data_dir = 'age_dataset/train'
valid_data_dir = 'age_dataset/valid'

input_shape = 256
batch_size = 1
num_classes = 8
epochs = 5
# num_of_test_samples = 3306

def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

train_gen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range=10,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=False,
   )

validation_gen = ImageDataGenerator(rescale=1./255)


train_batches = train_gen.flow_from_directory(
    train_data_dir,
    target_size=(input_shape, input_shape),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle= True)

validation_batches = validation_gen.flow_from_directory(
    valid_data_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False)

train_crops = crop_generator(train_batches, 224)
# validation_crops = crop_generator(validation_batches, 224)

print(train_batches.samples)
print(validation_batches.samples)

model = Sequential()
model.add(VGGFace(model='vgg16', include_top = False, input_shape=(224,224,3), pooling = 'avg'))
model.add(Dense(1000,activation='relu'))
model.add(Dropout(0.6))
model.add(Dense(100, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(8,activation='softmax'))
print(model.summary())

model.layers[0].trainable = False


# layers_output = [layer.output for layer in model.layers[:10]]


model.compile(optimizer=optimizers.Adam(lr=0.01), loss='categorical_crossentropy',
              metrics=['acc'])

checkpoint = ModelCheckpoint('model/weight_resnet.hdf5', monitor='val_acc', save_best_only=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,
                              patience=5, min_lr=0.000001, verbose=1, mode='auto')
early_stopping_monitor = EarlyStopping(monitor='val_acc',patience=30, verbose=1, mode='auto')

training = model.fit_generator(train_crops, steps_per_epoch = train_batches.samples // batch_size, epochs=epochs, validation_data=validation_batches,
                               validation_steps= validation_batches.samples // batch_size,
                               callbacks=[checkpoint, early_stopping_monitor, reduce_lr])

model.save('model/model_age_resnet.h5')




plt.plot(training.history['acc'])
plt.xlabel(['Epochcount'])
plt.plot(training.history['val_acc'])
plt.ylabel(['Accuracy'])
plt.savefig('accuracy.png')
plt.show()



plt.plot(training.history['loss'])
plt.xlabel(['Epochcount'])
plt.plot(training.history['val_loss'])
plt.ylabel(['Lossdata'])
plt.savefig('loss.png')
plt.show()









